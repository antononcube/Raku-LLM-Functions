Revision history for "LLM::Functions"

0.5.4 2025-11-28
    - Bug fix / refactor -- more robust configuration creation from a configuration object.

0.5.3 2025-11-18
    - Bug fix -- have to be more cautious when passing configurations path arguments.

0.5.2 2025-11-17
    - Added configuration attributes used by the OpenAI's "gpt-5*" models.

0.5.1 2025-10-07
    - More robust tools presence check.

0.5.0 2025-09-26
    - Unified handling of LLM-tools evaluation using &llm-synthesize.
    - Boolean argument :echo for &llm-synthesize.
    - (Concise) gist method for LLM::Function.

0.4.2 2025-09-23
    - More proper support and evaluation of LLM-tools.
        - Simpler interface.
    - Declaring dependency on "WWW::Gemini:ver<0.0.21+>".
        - See: https://github.com/antononcube/Raku-LLM-Functions/issues/4

0.4.1 2025-09-10
    - Support and evaluation of LLM-tools for ChatGPT and Gemini "flavors."

0.4.0 2025-08-18
    - Using a default text argument value ('') if the argument of &llm-function is a string or a list of strings.
    - Better default models and max-tokens default values.
    - Making &llm-function to produce functors by default.
        - I.e. callable LLM::Function objects.
    - The old Block functions can be also produced using :$type = 'Block'.

0.3.2 2025-08-07
    - Minor tweaks &llm-tool-definition.
    - Better max-tokens default values.

0.3.1 2025-05-19
    - Added the namespace "LLM::Tooling" with classes that facilitate LLM function calling.
        - LLM::Tool, LLM::ToolRequest, LLM::ToolResponse.
    - Added:
        - &sub-info for metadata extraction of a given sub
        - &llm-tool-definition for easier making LLM-tool specs
        - &generate-llm-tool-response for the tool responses to LLM requests
        - &llm-tool-request for making LLM::ToolRequest object from LLM "tool_calls" output

0.3.0 2025-05-04
    - Made the LLaMA configurations explicitly use "WWW::LLaMA".

0.2.0 2024-09-07
    - Implemented universal &llm-embedding.