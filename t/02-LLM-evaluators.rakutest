use v6.d;

use lib '.';
use lib './lib';

use LLM::Functions;

use Test;

plan *;

#===========================================================
## 1
#===========================================================
ok LLM::Functions::Evaluator.new;

#===========================================================
## 2
#===========================================================
ok LLM::Functions::Evaluator.new(conf => llm-configuration(Whatever));

#===========================================================
## 3
#===========================================================
ok LLM::Functions::EvaluatorChat.new(conf => llm-configuration(Whatever));

#===========================================================
## 4
#===========================================================
ok LLM::Functions::EvaluatorChat.new(conf => llm-configuration('PaLM'));

#===========================================================
## 5
#===========================================================
is-deeply
        llm-evaluator(llm-configuration('PaLM', api-user-id => 'u5')),
        LLM::Functions::Evaluator.new(conf => llm-configuration('PaLM', api-user-id => 'u5'));

#===========================================================
## 6
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'u6'),
        llm-evaluator(llm-configuration('PaLM', api-user-id => 'u6'));

#===========================================================
## 7
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'BrandNewUser3233'),
        llm-evaluator(llm-configuration('PaLM', api-user-id => 'BrandNewUser3233'));

#===========================================================
## 8
#===========================================================
is-deeply
        llm-evaluator('PaLM', formatron => Numeric, api-user-id => 'u8'),
        LLM::Functions::Evaluator.new(conf => llm-configuration('PaLM', api-user-id => 'u8'), formatron => Numeric);

#===========================================================
## 9
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'u9'),
        llm-evaluator(llm-evaluator('PaLM', api-user-id => 'u9'));

#===========================================================
## 10
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.', formatron => 'JSON'),
        llm-evaluator(
                Whatever,
                conf => llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON');

#===========================================================
## 11
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.', formatron => 'JSON'),
        llm-evaluator(
                conf => llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON');

#===========================================================
## 12
#===========================================================
is-deeply
        llm-evaluator('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.', formatron => 'JSON'),
        llm-evaluator(
                llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON');

#===========================================================
## 13
#===========================================================
is-deeply
        llm-evaluator(llm-evaluator('PaLM'), api-user-id => 'u9', prompts => 'You are the best data scientist.',
                formatron => 'JSON'),
        llm-evaluator(
                llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON');

#===========================================================
## 14
#===========================================================
is-deeply
        llm-evaluator(
                llm-evaluator(Whatever),
                conf => llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON'),
        llm-evaluator(
                llm-configuration('PaLM', api-user-id => 'u9', prompts => 'You are the best data scientist.'),
                formatron => 'JSON');

#===========================================================
## 15
#===========================================================
isa-ok llm-evaluator(llm-configuration('ChatPaLM'), llm-evaluator-class => LLM::Functions::EvaluatorChatPaLM),
        LLM::Functions::EvaluatorChatPaLM,
        'Expected ChatPaLM type';

#===========================================================
## 16-18
#===========================================================
my $evlr16 = llm-evaluator('PaLM', api-user-id => 'u16', prompts => 'You are the best data scientist.', formatron => 'JSON');

isa-ok $evlr16.Hash, Hash;

isa-ok $evlr16.Str, Str;

ok $evlr16.gist;

#===========================================================
## 19
#===========================================================
my $conf19 = 'Llama';
my $prompt19 = 'Given a topic, write emails in a concise, professional manner.';

my $llm-evaluator19 = llm-evaluator($conf19,
        conf => llm-configuration($conf19, prompts => $prompt19, temperature => 0.01),
        formatron => 'JSON');

is $llm-evaluator19.conf.prompts, [$prompt19,], 'Same prompt';

done-testing;
