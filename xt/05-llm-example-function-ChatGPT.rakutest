use v6.d;

# use lib <. lib>;

use LLM::Functions;

use Test;

my $llm-evaluator = llm-configuration('ChatGPT', model => 'gpt-3.5-turbo', :100max-tokens, temperature => 0.4);

plan *;

## 1
ok llm-example-function(<finger hand> => <hand arm>, :$llm-evaluator)('foot');

## 2
isa-ok llm-example-function('<| A->3, 4->K1 |>' => '{ A:3, 4:K1 }')('<| 23->3, G->33, T -> R5|>', :$llm-evaluator), Str;

## 3
is-deeply
        llm-example-function('<| A->3, 4->K1 |>' => '{ "A":3, "4":"K1" }', form => 'JSON', :$llm-evaluator)('<| 23->3, G->33, T -> R5|>'),
        ${"23" => 3, :G(33), :T("R5")};

## 4
isa-ok llm-example-function({ "crocodile" => "grasshopper", "fox" => "cardinal" }, hint => 'animal colors', :$llm-evaluator)('raccoon'),
        Str;

## 5
is llm-example-function(((1 .. 4) Z=> 11 «*« (1 .. 4)), :$llm-evaluator)(8).trim, '88';

## 6
is llm-example-function(((1 .. 4) Z=> 11 «*« (1 .. 4)), e => $llm-evaluator, form => { with $_ ~~ / \d+ / { $/.Int } })(8), 88;

done-testing;
